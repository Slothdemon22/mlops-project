{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "model_path = \"/content/drive/MyDrive/transfer_learning_model_Xception/best_model.keras\"  # your best model\n",
    "img_path   = \"/content/6.png\"  # replace with your image\n",
    "\n",
    "# =========================\n",
    "# Load Model\n",
    "# =========================\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# =========================\n",
    "# Preprocess Image\n",
    "# =========================\n",
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # make batch of 1\n",
    "img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
    "\n",
    "# =========================\n",
    "# Predict\n",
    "# =========================\n",
    "pred = model.predict(img_array)\n",
    "class_index = np.argmax(pred, axis=1)[0]\n",
    "confidence = pred[0][class_index] * 100\n",
    "\n",
    "# =========================\n",
    "# Map class index to label\n",
    "# =========================\n",
    "class_labels = {0: \"fake\", 1: \"real\"}  # make sure this matches your dataset\n",
    "predicted_label = class_labels[class_index]\n",
    "\n",
    "print(f\"Prediction: {predicted_label} ({confidence:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9167ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All-in-one: extract @2 FPS, preprocess correctly (256x256), predict, diagnostics\n",
    "import os, cv2, numpy as np, tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODEL_PATH = \"/content/drive/MyDrive/transfer_learning_model_Xception/best_model.keras\"\n",
    "VIDEO_PATH = \"/content/4.mp4\"   # your uploaded video\n",
    "FRAMES_DIR = \"/content/frames_extracted\"\n",
    "FPS_TO_EXTRACT = 2                 # 2 frames per second\n",
    "IMG_SIZE = (256, 256)               # <-- MUST match training\n",
    "THRESHOLD = 0.5                     # threshold used for binary decision (not final arbiter)\n",
    "TOP_K_TO_SHOW = 6                   # show top K most-fake frames as diagnostics\n",
    "# -----------------------------\n",
    "\n",
    "# load model\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded:\", MODEL_PATH)\n",
    "\n",
    "# helper: extract frames at target FPS\n",
    "def extract_frames(video_path, out_dir, fps_target=2):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Cannot open video: \" + video_path)\n",
    "    src_fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    frame_interval = max(1, int(round(src_fps / fps_target)))\n",
    "    frame_idx = 0\n",
    "    saved = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if (frame_idx % frame_interval) == 0:\n",
    "            path = os.path.join(out_dir, f\"frame_{saved:05d}.jpg\")\n",
    "            cv2.imwrite(path, frame)            # original BGR saved\n",
    "            saved += 1\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    print(f\"ðŸ“¸ Extracted {saved} frames at ~{fps_target} FPS (src_fps={src_fps:.2f})\")\n",
    "    return saved\n",
    "\n",
    "# preprocess + predict one frame -> returns (prob_fake, prob_real)\n",
    "def predict_frame_probs(img_path):\n",
    "    # load -> resize -> convert to array\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    arr = image.img_to_array(img)             # float32\n",
    "    # use EfficientNet preprocessing (matches training)\n",
    "    arr = tf.keras.applications.efficientnet.preprocess_input(arr)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    preds = model.predict(arr, verbose=0)[0]  # shape (2,) for softmax [p_fake, p_real]\n",
    "    # defensively handle shapes\n",
    "    if len(preds) == 1:\n",
    "        # binary single-output sigmoid case (unlikely here)\n",
    "        p_fake = preds[0]\n",
    "        p_real = 1.0 - p_fake\n",
    "    else:\n",
    "        p_fake, p_real = float(preds[0]), float(preds[1])\n",
    "    return p_fake, p_real\n",
    "\n",
    "# run extraction\n",
    "if os.path.exists(FRAMES_DIR):\n",
    "    # optional: clear old frames to avoid confusion\n",
    "    shutil.rmtree(FRAMES_DIR)\n",
    "num = extract_frames(VIDEO_PATH, FRAMES_DIR, FPS_TO_EXTRACT)\n",
    "if num == 0:\n",
    "    raise RuntimeError(\"No frames extracted â€” check VIDEO_PATH or video FPS.\")\n",
    "\n",
    "# predict on all frames (batch in groups for speed)\n",
    "frame_files = sorted(glob(os.path.join(FRAMES_DIR, \"*.jpg\")))\n",
    "probs = []\n",
    "for p in frame_files:\n",
    "    p_fake, p_real = predict_frame_probs(p)\n",
    "    probs.append((p, p_fake, p_real))\n",
    "\n",
    "# stats & aggregation\n",
    "p_fakes = np.array([x[1] for x in probs])\n",
    "p_reals = np.array([x[2] for x in probs])\n",
    "\n",
    "mean_fake = p_fakes.mean()\n",
    "median_fake = np.median(p_fakes)\n",
    "mean_real = p_reals.mean()\n",
    "median_real = np.median(p_reals)\n",
    "\n",
    "# majority vote by frame (>0.5 => fake)\n",
    "votes = (p_fakes > 0.5).sum()\n",
    "vote_frac_fake = votes / len(p_fakes)\n",
    "\n",
    "print(\"\\n=== Frame-level summary ===\")\n",
    "print(\"Frames evaluated:\", len(p_fakes))\n",
    "print(f\"Mean P(fake): {mean_fake:.4f}   Mean P(real): {mean_real:.4f}\")\n",
    "print(f\"Median P(fake): {median_fake:.4f}   Median P(real): {median_real:.4f}\")\n",
    "print(f\"Fraction frames voted FAKE (>0.5): {vote_frac_fake:.3f} ({votes}/{len(p_fakes)})\")\n",
    "\n",
    "# decide final: combine metrics (you can pick strategy)\n",
    "# Strategy: if mean_fake > 0.5 or vote_frac_fake > 0.5 or median_fake > 0.5 => FAKE, else REAL\n",
    "is_fake_final = (mean_fake > 0.5) or (vote_frac_fake > 0.5) or (median_fake > 0.5)\n",
    "final_label = \"FAKE (AI-generated)\" if is_fake_final else \"REAL (Camera)\"\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(\"ðŸŽ¥ FINAL VIDEO CLASSIFICATION:\", final_label)\n",
    "print(\"===================================\\n\")\n",
    "\n",
    "# Diagnostic: show top-K frames by P(fake)\n",
    "sorted_by_fake = sorted(probs, key=lambda x: x[1], reverse=True)\n",
    "print(f\"Top {TOP_K_TO_SHOW} frames with highest P(fake):\")\n",
    "for i, (path, pf, pr) in enumerate(sorted_by_fake[:TOP_K_TO_SHOW]):\n",
    "    print(f\"{i+1:02d}. {os.path.basename(path)}  P(fake)={pf:.4f}  P(real)={pr:.4f}\")\n",
    "\n",
    "# Save per-frame CSV\n",
    "import csv\n",
    "csv_out = os.path.join(FRAMES_DIR, \"frame_predictions.csv\")\n",
    "with open(csv_out, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"frame\", \"p_fake\", \"p_real\"])\n",
    "    for (path, pf, pr) in probs:\n",
    "        writer.writerow([os.path.basename(path), f\"{pf:.6f}\", f\"{pr:.6f}\"])\n",
    "print(\"\\nSaved per-frame predictions to:\", csv_out)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
