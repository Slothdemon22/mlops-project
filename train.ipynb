{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Source zip in Drive\n",
        "drive_zip_path = \"/content/drive/MyDrive/massive-ai-vs-real.zip\"\n",
        "\n",
        "# Target extract location\n",
        "target_dir = \"/content/data\"\n",
        "\n",
        "# Remove old folder if it exists\n",
        "if os.path.exists(target_dir):\n",
        "    print(\"‚ôªÔ∏è Removing old /content/data directory...\")\n",
        "    shutil.rmtree(target_dir)\n",
        "\n",
        "# Recreate clean folder\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Extract fresh dataset\n",
        "print(\"üì¶ Extracting dataset to /content/data ...\")\n",
        "with zipfile.ZipFile(drive_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_dir)\n",
        "\n",
        "print(\"‚úÖ Extraction complete! Fresh dataset is ready at /content/data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-zXPSobGcr3k",
        "outputId": "55952b3b-6d23-4c98-b891-530513c9d2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚ôªÔ∏è Removing old /content/data directory...\n",
            "üì¶ Extracting dataset to /content/data ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-639261715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üì¶ Extracting dataset to /content/data ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_zip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Extraction complete! Fresh dataset is ready at /content/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mfsrc_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[1;32m   1086\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B33sJblCF0AH",
        "outputId": "7866b09d-4a46-4ca6-defb-acbcc179120c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "# 1Ô∏è‚É£ Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2Ô∏è‚É£ Define paths\n",
        "zip_path = \"/content/drive/MyDrive/cleaned_dataset.zip\"   # your uploaded zip file\n",
        "extract_path = \"/content/data\"   # where to unzip it\n",
        "\n",
        "# 3Ô∏è‚É£ Make sure the extract folder exists\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# 4Ô∏è‚É£ Unzip\n",
        "print(f\"üì¶ Unzipping dataset to: {extract_path}\")\n",
        "start = time.time()\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"‚úÖ Unzip complete in {time.time() - start:.2f}s\")\n",
        "print(f\"üìÅ Dataset ready at: {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylXsWarlOAj4",
        "outputId": "ca0cec31-8da9-4bbf-ec8b-2f8f54cbf4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üì¶ Unzipping dataset to: /content/data\n",
            "‚úÖ Unzip complete in 23.05s\n",
            "üìÅ Dataset ready at: /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Force remounting Google Drive to refresh credentials\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9BLD1vxXYZFO",
        "outputId": "6e77465b-67e6-4a5b-e073-2cd9d4f7e2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1063711811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Force remounting Google Drive to refresh credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "drive_zip = \"/content/drive/MyDrive/massive-ai-vs-real.zip\"\n",
        "target_dir = \"/content/data/train/real\"\n",
        "\n",
        "print(\"üì¶ Extracting only train/real from ZIP...\")\n",
        "\n",
        "# Clean up target if exists\n",
        "if os.path.exists(target_dir):\n",
        "    shutil.rmtree(target_dir)\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(drive_zip, 'r') as zip_ref:\n",
        "    # Filter files that are in train/real/\n",
        "    members = [m for m in zip_ref.namelist() if m.startswith(\"train/real/\") and not m.endswith(\"/\")]\n",
        "    for member in members:\n",
        "        # Extract only these files\n",
        "        zip_ref.extract(member, \"/content/data\")\n",
        "\n",
        "print(\"‚úÖ Extraction complete! Folder ready at:\", target_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "7E9fnF3Zc_NW",
        "outputId": "51643a1d-c167-4195-f560-033c7e67d485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting only train/real from ZIP...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-778932605.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Extract only these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Extraction complete! Folder ready at:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, pwd)\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mfsrc_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[1;32m   1086\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Paths to your folders\n",
        "real_dir = \"/content/data/train/real\"\n",
        "fake_dir = \"/content/data/train/fake\"\n",
        "\n",
        "# Get list of image files\n",
        "real_images = [f for f in os.listdir(real_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "fake_images = [f for f in os.listdir(fake_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "real_count = len(real_images)\n",
        "fake_count = len(fake_images)\n",
        "\n",
        "print(f\"Before balancing:\")\n",
        "print(f\"  Real: {real_count}\")\n",
        "print(f\"  Fake: {fake_count}\")\n",
        "\n",
        "# Determine which to trim\n",
        "if real_count < fake_count:\n",
        "    # Too many fakes ‚Äî remove extras\n",
        "    to_remove = fake_count - real_count\n",
        "    remove_files = random.sample(fake_images, to_remove)\n",
        "    for file in remove_files:\n",
        "        os.remove(os.path.join(fake_dir, file))\n",
        "    print(f\"Removed {to_remove} fake images.\")\n",
        "elif fake_count < real_count:\n",
        "    # Too many reals ‚Äî remove extras\n",
        "    to_remove = real_count - fake_count\n",
        "    remove_files = random.sample(real_images, to_remove)\n",
        "    for file in remove_files:\n",
        "        os.remove(os.path.join(real_dir, file))\n",
        "    print(f\"Removed {to_remove} real images.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already balanced!\")\n",
        "\n",
        "# Recount\n",
        "final_real = len(os.listdir(real_dir))\n",
        "final_fake = len(os.listdir(fake_dir))\n",
        "print(f\"\\nAfter balancing:\")\n",
        "print(f\"  Real: {final_real}\")\n",
        "print(f\"  Fake: {final_fake}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH5sookynyuO",
        "outputId": "f3594924-2915-4d17-ebb0-f280995bb900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before balancing:\n",
            "  Real: 13961\n",
            "  Fake: 24000\n",
            "Removed 10039 fake images.\n",
            "\n",
            "After balancing:\n",
            "  Real: 13961\n",
            "  Fake: 13961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# Paths\n",
        "test_root = \"/content/data/test\"\n",
        "val_root = \"/content/data/val\"\n",
        "\n",
        "# Create val folders if not exist\n",
        "os.makedirs(val_root, exist_ok=True)\n",
        "\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    src = os.path.join(test_root, category)\n",
        "    dst = os.path.join(val_root, category)\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "    # Get image list and shuffle\n",
        "    files = [f for f in os.listdir(src) if os.path.isfile(os.path.join(src, f))]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    # Split exactly in half\n",
        "    half = floor(len(files) / 2)\n",
        "    val_files = files[:half]\n",
        "    test_files = files[half:]\n",
        "\n",
        "    # Move half to val folder\n",
        "    for f in val_files:\n",
        "        shutil.move(os.path.join(src, f), os.path.join(dst, f))\n",
        "\n",
        "    print(f\"‚úÖ Moved {len(val_files)} shuffled images from {src} ‚Üí {dst}\")\n",
        "    print(f\"üß© Remaining in test: {len(test_files)} images\")\n",
        "\n",
        "print(\"\\nSplit complete ‚Äî val and test sets are now equal halves with no overlap.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFtaBRjzdHuc",
        "outputId": "55b55f8a-796b-4392-f512-7a60662fca34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Moved 3000 shuffled images from /content/data/test/real ‚Üí /content/data/val/real\n",
            "üß© Remaining in test: 3000 images\n",
            "‚úÖ Moved 3000 shuffled images from /content/data/test/fake ‚Üí /content/data/val/fake\n",
            "üß© Remaining in test: 3000 images\n",
            "\n",
            "Split complete ‚Äî val and test sets are now equal halves with no overlap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Path to your zip file in Drive\n",
        "zip_path = \"/content/drive/MyDrive/massive-ai-vs-real.zip\"\n",
        "\n",
        "# Destination folder in Colab\n",
        "unzip_dest = \"/content/AI_vs_Real_raw\"\n",
        "os.makedirs(unzip_dest, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "m8kWFFEcXiZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"{zip_path}\" -d \"{unzip_dest}\"\n"
      ],
      "metadata": {
        "id": "llDMZkxQY1JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmHJTIj_cFWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "old_root = \"/content/AI_vs_Real_raw\"\n",
        "new_root = \"/content/data\"\n",
        "\n",
        "if os.path.exists(old_root):\n",
        "    if os.path.exists(new_root):\n",
        "        print(f\"‚ùå Folder '{new_root}' already exists ‚Äî remove or rename it first.\")\n",
        "    else:\n",
        "        shutil.move(old_root, new_root)\n",
        "        print(f\"‚úÖ Dataset root renamed from '{old_root}' to '{new_root}'\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Folder '{old_root}' not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOiYk-Vb90b",
        "outputId": "f8f9c44c-258f-4578-d189-fed985be6e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset root renamed from '/content/AI_vs_Real_raw' to '/content/data'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = {\n",
        "    \"Train Real\": \"/content/data/train/real\",\n",
        "    \"Train Fake\": \"/content/data/train/fake\",\n",
        "    \"Test Real\": \"/content/data/test/real\",\n",
        "    \"Test Fake\": \"/content/data/test/fake\"\n",
        "}\n",
        "\n",
        "for name, path in folders.items():\n",
        "    if os.path.exists(path):\n",
        "        count = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "        print(f\"{name}: {count} images\")\n",
        "    else:\n",
        "        print(f\"{name}: Folder not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YivLfc3lwfFz",
        "outputId": "a9907f5f-42a5-4558-bf47-5e4f6d0ebb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Real: 13961 images\n",
            "Train Fake: 13961 images\n",
            "Test Real: 3000 images\n",
            "Test Fake: 3000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "test_root = \"/content/AI_vs_Real_128x128/test\"\n",
        "val_root = \"/content/AI_vs_Real_128x128/val\"\n",
        "\n",
        "# Ensure val folders exist\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(val_root, category), exist_ok=True)\n",
        "\n",
        "# Split each category\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    test_folder = os.path.join(test_root, category)\n",
        "    val_folder = os.path.join(val_root, category)\n",
        "\n",
        "    files = [f for f in os.listdir(test_folder) if os.path.isfile(os.path.join(test_folder, f))]\n",
        "    random.shuffle(files)  # shuffle to get random half\n",
        "\n",
        "    split_index = len(files) // 2\n",
        "    val_files = files[:split_index]\n",
        "\n",
        "    # Move half to val folder\n",
        "    for f in val_files:\n",
        "        src_path = os.path.join(test_folder, f)\n",
        "        dst_path = os.path.join(val_folder, f)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "    print(f\"{category}: moved {len(val_files)} files from test ‚Üí val\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "InG3yTkhanYK",
        "outputId": "2d0dc828-3228-4891-9a86-f6d2c273644a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/AI_vs_Real_128x128/test/real'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1443446507.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mval_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shuffle to get random half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AI_vs_Real_128x128/test/real'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = {\n",
        "    \"Train Real\": \"/content/data/train/real\",\n",
        "    \"Train Fake\": \"/content/data/train/fake\",\n",
        "    \"Test Real\": \"/content/data/test/real\",\n",
        "    \"Test Fake\": \"/content/data/test/fake\",\n",
        "    \"Val Real\": \"/content/data/val/real\",\n",
        "    \"Val Fake\": \"/content/data/val/fake\"\n",
        "}\n",
        "\n",
        "for name, path in folders.items():\n",
        "    if os.path.exists(path):\n",
        "        count = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "        print(f\"{name}: {count} images\")\n",
        "    else:\n",
        "        print(f\"{name}: Folder not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBqgEvNY09Y3",
        "outputId": "5cebc6c6-a9aa-4dbd-f1c1-f840bd256848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Real: 13953 images\n",
            "Train Fake: 13960 images\n",
            "Test Real: 2998 images\n",
            "Test Fake: 3000 images\n",
            "Val Real: 2999 images\n",
            "Val Fake: 3000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Base dataset directory\n",
        "base_dir = \"/content/data\"\n",
        "\n",
        "# Define all subdirectories\n",
        "data_dirs = [\n",
        "    os.path.join(base_dir, \"train/real\"),\n",
        "    os.path.join(base_dir, \"train/fake\"),\n",
        "    os.path.join(base_dir, \"test/real\"),\n",
        "    os.path.join(base_dir, \"test/fake\"),\n",
        "    os.path.join(base_dir, \"val/real\"),\n",
        "    os.path.join(base_dir, \"val/fake\"),\n",
        "]\n",
        "\n",
        "total_size = 0  # in bytes\n",
        "\n",
        "print(\"üì¶ Dataset Folder Sizes:\\n\")\n",
        "\n",
        "for folder in data_dirs:\n",
        "    folder_size = 0\n",
        "    for f in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            folder_size += os.path.getsize(file_path)\n",
        "    total_size += folder_size\n",
        "    print(f\"{folder}: {folder_size / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "print(f\"\\nüíæ Total dataset size: {total_size / (1024 * 1024 * 1024):.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWWJecHD7E0l",
        "outputId": "352c68dd-e9ce-4a32-9684-20d625b072a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Dataset Folder Sizes:\n",
            "\n",
            "/content/data/train/real: 262.71 MB\n",
            "/content/data/train/fake: 287.13 MB\n",
            "/content/data/test/real: 54.85 MB\n",
            "/content/data/test/fake: 61.15 MB\n",
            "/content/data/val/real: 54.41 MB\n",
            "/content/data/val/fake: 61.95 MB\n",
            "\n",
            "üíæ Total dataset size: 0.76 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Dataset directories in correct order\n",
        "data_dirs = [\n",
        "    \"/content/data/test/real\",\n",
        "    \"/content/data/test/fake\",\n",
        "    \"/content/data/val/real\",\n",
        "    \"/content/data/val/fake\",\n",
        "    \"/content/data/train/real\",\n",
        "    \"/content/data/train/fake\",\n",
        "]\n",
        "\n",
        "target_size = (256, 256)  # Resize target\n",
        "total_removed = 0\n",
        "\n",
        "print(\"üßπ Cleaning and resizing dataset...\\n\")\n",
        "\n",
        "for folder in data_dirs:\n",
        "    removed_count = 0\n",
        "    processed_count = 0\n",
        "\n",
        "    files = os.listdir(folder)\n",
        "    total_files = len(files)\n",
        "\n",
        "    if total_files == 0:\n",
        "        print(f\"‚ö†Ô∏è  Skipping empty folder: {folder}\\n\")\n",
        "        continue\n",
        "\n",
        "    batch_start_time = time.time()\n",
        "\n",
        "    for idx, file_name in enumerate(files, start=1):\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        try:\n",
        "            # Validate image\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()\n",
        "\n",
        "            # Reopen to resize\n",
        "            with Image.open(file_path) as img:\n",
        "                img = img.convert(\"RGB\")\n",
        "                if img.size != target_size:\n",
        "                    img = img.resize(target_size)\n",
        "                    img.save(file_path, format=\"JPEG\", quality=90)\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "        except (IOError, SyntaxError, UnidentifiedImageError):\n",
        "            os.remove(file_path)\n",
        "            removed_count += 1\n",
        "\n",
        "        # Show progress every 50 images or at the end\n",
        "        if idx % 50 == 0 or idx == total_files:\n",
        "            elapsed = time.time() - batch_start_time\n",
        "            print(f\"[{folder}] {idx}/{total_files} processed ‚Äî Batch time: {elapsed:.2f}s\")\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "    total_removed += removed_count\n",
        "    print(f\"‚úÖ {folder} ‚Üí Cleaned: {processed_count}, Removed corrupted: {removed_count}\\n\")\n",
        "\n",
        "print(f\"\\nüöÄ Total corrupted images removed across all folders: {total_removed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x96KiYLx5-Q8",
        "outputId": "0170fa33-ffa2-41f8-b3eb-4d3d14d5f95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning and resizing dataset...\n",
            "\n",
            "[/content/data/test/real] 50/2998 processed ‚Äî Batch time: 0.08s\n",
            "[/content/data/test/real] 100/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 150/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 200/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 250/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 300/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 350/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 400/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 450/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 500/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 550/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 600/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 650/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 700/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 750/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 800/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 850/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 900/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 950/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 1000/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1050/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 1100/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1150/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1200/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1250/2998 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/test/real] 1300/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 1350/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1400/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1450/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1500/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1550/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1600/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1650/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1700/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1750/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1800/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1850/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1900/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 1950/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2000/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2050/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2100/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2150/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2200/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2250/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 2300/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2350/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2400/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2450/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2500/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2550/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 2600/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2650/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2700/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2750/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2800/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2850/2998 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/real] 2900/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2950/2998 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/real] 2998/2998 processed ‚Äî Batch time: 0.03s\n",
            "‚úÖ /content/data/test/real ‚Üí Cleaned: 2998, Removed corrupted: 0\n",
            "\n",
            "[/content/data/test/fake] 50/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 100/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 150/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 200/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 250/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 300/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 350/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 400/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 450/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 500/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 550/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 600/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 650/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 700/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 750/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 800/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 850/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 900/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 950/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1000/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1050/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1100/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1150/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 1200/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 1250/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1300/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1350/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 1400/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 1450/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 1500/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1550/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1600/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1650/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1700/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1750/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1800/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1850/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1900/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 1950/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2000/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2050/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2100/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2150/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2200/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2250/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2300/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2350/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2400/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2450/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 2500/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 2550/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2600/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2650/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2700/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2750/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2800/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 2850/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2900/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/test/fake] 2950/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/test/fake] 3000/3000 processed ‚Äî Batch time: 0.03s\n",
            "‚úÖ /content/data/test/fake ‚Üí Cleaned: 3000, Removed corrupted: 0\n",
            "\n",
            "[/content/data/val/real] 50/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 100/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 150/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 200/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 250/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 300/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 350/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 400/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 450/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 500/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 550/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 600/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 650/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 700/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 750/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 800/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 850/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 900/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 950/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1000/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1050/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 1100/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1150/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1200/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1250/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1300/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1350/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1400/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1450/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1500/2999 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/real] 1550/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 1600/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 1650/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 1700/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1750/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1800/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 1850/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1900/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 1950/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2000/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2050/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2100/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2150/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2200/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2250/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2300/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2350/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2400/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2450/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2500/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 2550/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2600/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2650/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2700/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2750/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 2800/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 2850/2999 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/real] 2900/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2950/2999 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/real] 2999/2999 processed ‚Äî Batch time: 0.04s\n",
            "‚úÖ /content/data/val/real ‚Üí Cleaned: 2999, Removed corrupted: 0\n",
            "\n",
            "[/content/data/val/fake] 50/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 100/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 150/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 200/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 250/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 300/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 350/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 400/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 450/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 500/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 550/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 600/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 650/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 700/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 750/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 800/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 850/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 900/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 950/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1000/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1050/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 1100/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 1150/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 1200/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1250/3000 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/val/fake] 1300/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1350/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1400/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 1450/3000 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/val/fake] 1500/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1550/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1600/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1650/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1700/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1750/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1800/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1850/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1900/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 1950/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2000/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2050/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2100/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2150/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2200/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2250/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2300/3000 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/val/fake] 2350/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2400/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2450/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2500/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2550/3000 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/val/fake] 2600/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2650/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2700/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2750/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2800/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2850/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2900/3000 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/val/fake] 2950/3000 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/val/fake] 3000/3000 processed ‚Äî Batch time: 0.05s\n",
            "‚úÖ /content/data/val/fake ‚Üí Cleaned: 3000, Removed corrupted: 0\n",
            "\n",
            "[/content/data/train/real] 50/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 100/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 150/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 200/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 250/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 300/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 350/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 400/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 450/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 500/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 550/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 600/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 650/13953 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/real] 700/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 750/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 800/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 850/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 900/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 950/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1000/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1050/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1100/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1150/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 1200/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 1250/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1300/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1350/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1400/13953 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/real] 1450/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1500/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1550/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1600/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1650/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 1700/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 1750/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 1800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 1850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 1900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 1950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2150/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 2200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2350/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 2400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2700/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 2750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 2950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3100/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 3150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3250/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 3300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3800/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 3850/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 3900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 3950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4600/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 4650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 4800/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 4850/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 4900/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 4950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5300/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 5350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 5950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6250/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 6300/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 6350/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 6400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6650/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 6700/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 6750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 6950/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 7000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7100/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 7150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7250/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 7300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7600/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 7650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7800/13953 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/real] 7850/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 7900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 7950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8200/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 8250/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 8300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8600/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 8650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 8950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9050/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 9100/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 9150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9300/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 9350/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 9400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9650/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 9700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 9950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10000/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 10050/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 10100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10700/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 10750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10800/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 10850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 10950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11150/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 11200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11500/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 11550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11600/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 11650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 11950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12350/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 12400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12600/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 12650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 12950/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13000/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13050/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13100/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13150/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13200/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13250/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13300/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13350/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13400/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13450/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13500/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13550/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13600/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13650/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13700/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13750/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13800/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13850/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13900/13953 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/real] 13950/13953 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/real] 13953/13953 processed ‚Äî Batch time: 0.00s\n",
            "‚úÖ /content/data/train/real ‚Üí Cleaned: 13953, Removed corrupted: 0\n",
            "\n",
            "[/content/data/train/fake] 50/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1650/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 1700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 1950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2200/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 2250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 2600/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 2650/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 2700/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 2750/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 2800/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 2850/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 2900/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 2950/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3000/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3050/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 3100/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3150/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3200/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3250/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3300/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3350/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3400/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3450/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3500/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3550/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3600/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3650/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3700/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3750/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3800/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3850/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3900/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 3950/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4000/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 4050/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 4100/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4150/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 4200/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 4250/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4300/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4350/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4400/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4450/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4500/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4550/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4600/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4650/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4700/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4750/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4800/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 4850/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4900/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 4950/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5000/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5050/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5100/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5150/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5200/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5250/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5300/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5350/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5400/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5450/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 5500/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5550/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5600/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5650/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5700/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5750/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5800/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5850/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5900/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 5950/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 6000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6200/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 6250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6400/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 6450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6650/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 6700/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 6750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 6950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7050/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 7100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7700/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 7750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 7900/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 7950/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 8000/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 8050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8100/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 8150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8300/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 8350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 8950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9150/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9450/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9500/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9550/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9600/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9850/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 9900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 9950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10250/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 10300/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 10350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10550/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 10600/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 10650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10850/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 10900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 10950/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 11000/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11250/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 11300/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 11350/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 11400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11450/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11500/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 11750/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 11800/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 11850/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 11900/13960 processed ‚Äî Batch time: 0.08s\n",
            "[/content/data/train/fake] 11950/13960 processed ‚Äî Batch time: 0.07s\n",
            "[/content/data/train/fake] 12000/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 12050/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 12100/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 12150/13960 processed ‚Äî Batch time: 0.09s\n",
            "[/content/data/train/fake] 12200/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 12250/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 12300/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 12350/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 12400/13960 processed ‚Äî Batch time: 0.05s\n",
            "[/content/data/train/fake] 12450/13960 processed ‚Äî Batch time: 0.06s\n",
            "[/content/data/train/fake] 12500/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 12550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12600/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 12650/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 12700/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12750/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12800/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12850/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12900/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 12950/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13000/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13050/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13100/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13150/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13200/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13250/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13300/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13350/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13400/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13450/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13500/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13550/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13600/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13650/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13700/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13750/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13800/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13850/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13900/13960 processed ‚Äî Batch time: 0.04s\n",
            "[/content/data/train/fake] 13950/13960 processed ‚Äî Batch time: 0.03s\n",
            "[/content/data/train/fake] 13960/13960 processed ‚Äî Batch time: 0.01s\n",
            "‚úÖ /content/data/train/fake ‚Üí Cleaned: 13960, Removed corrupted: 0\n",
            "\n",
            "\n",
            "üöÄ Total corrupted images removed across all folders: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import time\n",
        "\n",
        "dataset_dir = \"/content/data\"\n",
        "zip_path = \"/content/cleaned_dataset.zip\"\n",
        "\n",
        "start = time.time()\n",
        "print(\"üì¶ Zipping cleaned dataset...\")\n",
        "\n",
        "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', dataset_dir)\n",
        "\n",
        "print(f\"‚úÖ Zipped to {zip_path} in {time.time() - start:.2f} seconds.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2nqbj-Koill",
        "outputId": "b4dba277-8692-4972-da32-2cb92c97f58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Zipping cleaned dataset...\n",
            "‚úÖ Zipped to /content/cleaned_dataset.zip in 41.05 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "drive_target = \"/content/drive/MyDrive/cleaned_dataset.zip\"\n",
        "shutil.copy(zip_path, drive_target)\n",
        "\n",
        "print(f\"‚òÅÔ∏è Uploaded to Google Drive at: {drive_target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOHTAsoEolMn",
        "outputId": "8e335597-9a04-4d02-edce-eea8b2cb3bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚òÅÔ∏è Uploaded to Google Drive at: /content/drive/MyDrive/cleaned_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "\n",
        "# Dataset directories\n",
        "data_dirs = [\n",
        "    \"/content/data/test/real\",\n",
        "    \"/content/data/test/fake\",\n",
        "    \"/content/data/val/real\",\n",
        "    \"/content/data/val/fake\",\n",
        "    \"/content/data/train/fake\",\n",
        "    \"/content/data/train/real\",\n",
        "]\n",
        "\n",
        "corrupted_count = 0\n",
        "\n",
        "for folder in data_dirs:\n",
        "    folder_corrupted = 0\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Folder not found: {folder}\")\n",
        "        continue\n",
        "\n",
        "    files = os.listdir(folder)\n",
        "    if not files:\n",
        "        print(f\"No files in folder: {folder}\")\n",
        "        continue\n",
        "\n",
        "    for file_name in files:\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        if not os.path.isfile(file_path):\n",
        "            continue  # skip subfolders or non-files\n",
        "\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # quick corruption check\n",
        "        except (IOError, SyntaxError, UnidentifiedImageError):\n",
        "            print(f\"Corrupted: {file_path}\")\n",
        "            corrupted_count += 1\n",
        "            folder_corrupted += 1\n",
        "\n",
        "    print(f\"Folder {folder} ‚Üí Corrupted images found: {folder_corrupted}\")\n",
        "\n",
        "print(f\"\\nTotal corrupted images in dataset: {corrupted_count}\")\n"
      ],
      "metadata": {
        "id": "1hcVjEyt6aKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import time\n",
        "\n",
        "# ‚úÖ Source folders in Colab\n",
        "source_dirs = [\n",
        "    \"/content/data/test/real\",\n",
        "    \"/content/data/test/fake\",\n",
        "    \"/content/data/val/real\",\n",
        "    \"/content/data/val/fake\",\n",
        "    \"/content/data/train/real\",\n",
        "    \"/content/data/train/fake\",\n",
        "]\n",
        "\n",
        "# ‚úÖ Destination root in Drive\n",
        "target_root = \"/content/drive/MyDrive/AI_vs_Real_256x256\"\n",
        "target_size = (256, 256)\n",
        "batch_size = 50  # show progress every 50 images\n",
        "\n",
        "print(\"\\nüöÄ Copying and resizing dataset from Colab ‚Üí Google Drive (256x256)...\\n\")\n",
        "\n",
        "for src_folder in source_dirs:\n",
        "    folder_name = os.path.basename(src_folder)           # real / fake\n",
        "    parent_folder = os.path.basename(os.path.dirname(src_folder))  # train / test / val\n",
        "    target_folder = os.path.join(target_root, parent_folder, folder_name)\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "    files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
        "    total_files = len(files)\n",
        "\n",
        "    processed_count = 0\n",
        "    skipped_count = 0\n",
        "    batch_start = time.time()\n",
        "\n",
        "    for idx, file_name in enumerate(files, start=1):\n",
        "        src_path = os.path.join(src_folder, file_name)\n",
        "        target_path = os.path.join(target_folder, file_name)\n",
        "\n",
        "        try:\n",
        "            with Image.open(src_path) as img:\n",
        "                img = img.convert(\"RGB\").resize(target_size)\n",
        "                img.save(target_path, format=\"JPEG\", quality=90)\n",
        "            processed_count += 1\n",
        "\n",
        "        except (IOError, SyntaxError, UnidentifiedImageError):\n",
        "            skipped_count += 1\n",
        "            print(f\"‚ö†Ô∏è  Skipped corrupted file: {src_path}\")\n",
        "\n",
        "        # ‚úÖ Show progress every batch (only elapsed time)\n",
        "        if idx % batch_size == 0 or idx == total_files:\n",
        "            batch_time = time.time() - batch_start\n",
        "            print(f\"[{parent_folder}/{folder_name}] \"\n",
        "                  f\"Processed {idx}/{total_files} | Time since last batch: {batch_time:.2f}s\")\n",
        "            batch_start = time.time()\n",
        "\n",
        "    print(f\"‚úÖ Finished {parent_folder}/{folder_name} ‚Üí \"\n",
        "          f\"Processed: {processed_count}, Skipped: {skipped_count}\\n\")\n",
        "\n",
        "print(\"üéâ All folders processed and copied successfully to Google Drive (256x256)!\")\n"
      ],
      "metadata": {
        "id": "TzAKdS-dOWdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Source folder in Drive\n",
        "drive_folder = \"/content/drive/MyDrive/AI_vs_Real_128x128\"\n",
        "\n",
        "# Destination in Colab environment\n",
        "colab_folder = \"/content/AI_vs_Real_128x128\"\n",
        "\n",
        "# Copy entire folder from Drive to Colab\n",
        "if not os.path.exists(colab_folder):\n",
        "    shutil.copytree(drive_folder, colab_folder)\n",
        "else:\n",
        "    print(\"Folder already exists in Colab environment.\")\n",
        "\n",
        "print(f\"Dataset copied to {colab_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h34ER-PsOreF",
        "outputId": "e3433224-c3b1-4fe6-dba5-f9a79bd96084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Folder already exists in Colab environment.\n",
            "Dataset copied to /content/AI_vs_Real_128x128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "drive_root = \"/content/drive/MyDrive/AI_vs_Real_128x128\"\n",
        "\n",
        "for parent in [\"train\", \"test\", \"val\"]:\n",
        "    for sub in [\"real\", \"fake\"]:\n",
        "        folder = os.path.join(drive_root, parent, sub)\n",
        "        if os.path.exists(folder):\n",
        "            num_files = len(os.listdir(folder))\n",
        "            print(f\"{folder}: {num_files} files\")\n",
        "        else:\n",
        "            print(f\"{folder} does not exist!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsJsEBYhRBPh",
        "outputId": "dc188e55-8c26-4662-ec5a-2558c01a65c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_vs_Real_128x128/train/real does not exist!\n",
            "/content/drive/MyDrive/AI_vs_Real_128x128/train/fake: 1385 files\n",
            "/content/drive/MyDrive/AI_vs_Real_128x128/test/real: 2998 files\n",
            "/content/drive/MyDrive/AI_vs_Real_128x128/test/fake: 3000 files\n",
            "/content/drive/MyDrive/AI_vs_Real_128x128/val/real: 2999 files\n",
            "/content/drive/MyDrive/AI_vs_Real_128x128/val/fake: 3000 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "\n",
        "# ======================================\n",
        "# 1Ô∏è‚É£ Paths\n",
        "# ======================================\n",
        "train_dir = \"/content/data/train\"\n",
        "val_dir   = \"/content/data/val\"\n",
        "test_dir  = \"/content/data/test\"\n",
        "\n",
        "# ======================================\n",
        "# 2Ô∏è‚É£ Parameters\n",
        "# ======================================\n",
        "img_size = (256, 256)\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "# ======================================\n",
        "# 3Ô∏è‚É£ Load datasets efficiently\n",
        "# ======================================\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 4Ô∏è‚É£ Prefetch for speed\n",
        "# ======================================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# ======================================\n",
        "# 5Ô∏è‚É£ Data augmentation (real-time)\n",
        "# ======================================\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.15),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# ======================================\n",
        "# 6Ô∏è‚É£ Model ‚Äî EfficientNetB0 backbone\n",
        "# ======================================\n",
        "base_model = keras.applications.EfficientNetB0(\n",
        "    input_shape=img_size + (3,),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base_model.trainable = False  # freeze for transfer learning stage\n",
        "\n",
        "inputs = keras.Input(shape=img_size + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.efficientnet.preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# ======================================\n",
        "# 7Ô∏è‚É£ Compile\n",
        "# ======================================\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 8Ô∏è‚É£ Train (Phase 1: frozen backbone)\n",
        "# ======================================\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 9Ô∏è‚É£ Fine-tune (unfreeze top layers)\n",
        "# ======================================\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False  # unfreeze last 20 layers only\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# üîü Evaluate\n",
        "# ======================================\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save final model\n",
        "model.save(\"/content/drive/MyDrive/cleaned_dataset_model.h5\")\n"
      ],
      "metadata": {
        "id": "0W9ba8yVUvkA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "40f802ee-1a85-4b18-f4be-21de52cc28f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory /content/data/train",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1129801525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 3Ô∏è‚É£ Load datasets efficiently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# ======================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /content/data/train"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# =========================\n",
        "# üìÅ Paths\n",
        "# =========================\n",
        "train_dir = \"/content/data/train\"\n",
        "val_dir = \"/content/data/val\"\n",
        "test_dir = \"/content/data/test\"\n",
        "\n",
        "# Make sure Drive is mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/custom_cnn_real_vs_fake\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# ‚öôÔ∏è Parameters\n",
        "# =========================\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "\n",
        "# =========================\n",
        "# üîÑ Data Augmentation & Normalization\n",
        "# =========================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# =========================\n",
        "# üì¶ Load Datasets\n",
        "# =========================\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# üß© Custom CNN Model (256x256)\n",
        "# =========================\n",
        "def build_custom_cnn(input_shape=(256, 256, 3)):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_custom_cnn()\n",
        "\n",
        "# =========================\n",
        "# üß† Compile Model\n",
        "# =========================\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# üî• Callbacks ‚Äî ensures model saves no matter what\n",
        "# =========================\n",
        "checkpoint_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(save_dir, \"custom_cnn_best.keras\"),\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint_last = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(save_dir, \"custom_cnn_last.keras\"),\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.3, patience=3, verbose=1),\n",
        "    checkpoint_best,\n",
        "    checkpoint_last\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# üöÄ Train\n",
        "# =========================a\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Training interrupted ‚Äî saving model progress...\")\n",
        "    model.save(os.path.join(save_dir, \"custom_cnn_interrupted.keras\"))\n",
        "\n",
        "# =========================\n",
        "# ‚úÖ Evaluate on Test Set\n",
        "# =========================\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# =========================\n",
        "# üíæ Save Final Model\n",
        "# =========================\n",
        "final_path = os.path.join(save_dir, \"custom_cnn_final.keras\")\n",
        "model.save(final_path)\n",
        "print(f\"‚òÅÔ∏è Final model saved to Drive at: {final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaBEEweuFX5t",
        "outputId": "79adc915-9733-4d5c-f088-bbb21a90c8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 27913 images belonging to 2 classes.\n",
            "Found 5999 images belonging to 2 classes.\n",
            "Found 5998 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.6653 - loss: 0.7789\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75329, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 1: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 520ms/step - accuracy: 0.6653 - loss: 0.7788 - val_accuracy: 0.7533 - val_loss: 0.5058 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7361 - loss: 0.5407\n",
            "Epoch 2: val_accuracy improved from 0.75329 to 0.77063, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 2: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 507ms/step - accuracy: 0.7361 - loss: 0.5407 - val_accuracy: 0.7706 - val_loss: 0.4772 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.7654 - loss: 0.5058\n",
            "Epoch 3: val_accuracy improved from 0.77063 to 0.79513, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 3: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 513ms/step - accuracy: 0.7654 - loss: 0.5058 - val_accuracy: 0.7951 - val_loss: 0.4507 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.7786 - loss: 0.4823\n",
            "Epoch 4: val_accuracy improved from 0.79513 to 0.79713, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 4: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 511ms/step - accuracy: 0.7786 - loss: 0.4823 - val_accuracy: 0.7971 - val_loss: 0.4376 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7895 - loss: 0.4644\n",
            "Epoch 5: val_accuracy did not improve from 0.79713\n",
            "\n",
            "Epoch 5: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 501ms/step - accuracy: 0.7895 - loss: 0.4644 - val_accuracy: 0.7470 - val_loss: 0.5549 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8018 - loss: 0.4449\n",
            "Epoch 6: val_accuracy did not improve from 0.79713\n",
            "\n",
            "Epoch 6: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 497ms/step - accuracy: 0.8018 - loss: 0.4449 - val_accuracy: 0.7700 - val_loss: 0.5120 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8119 - loss: 0.4241\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.79713\n",
            "\n",
            "Epoch 7: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 498ms/step - accuracy: 0.8119 - loss: 0.4241 - val_accuracy: 0.7731 - val_loss: 0.4933 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8288 - loss: 0.3911\n",
            "Epoch 8: val_accuracy improved from 0.79713 to 0.80830, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 8: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 500ms/step - accuracy: 0.8288 - loss: 0.3911 - val_accuracy: 0.8083 - val_loss: 0.4251 - learning_rate: 3.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.8373 - loss: 0.3715\n",
            "Epoch 9: val_accuracy improved from 0.80830 to 0.82247, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 9: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 509ms/step - accuracy: 0.8373 - loss: 0.3715 - val_accuracy: 0.8225 - val_loss: 0.4016 - learning_rate: 3.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8467 - loss: 0.3674\n",
            "Epoch 10: val_accuracy did not improve from 0.82247\n",
            "\n",
            "Epoch 10: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 505ms/step - accuracy: 0.8467 - loss: 0.3674 - val_accuracy: 0.8086 - val_loss: 0.4414 - learning_rate: 3.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8499 - loss: 0.3550\n",
            "Epoch 11: val_accuracy did not improve from 0.82247\n",
            "\n",
            "Epoch 11: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 497ms/step - accuracy: 0.8499 - loss: 0.3550 - val_accuracy: 0.8135 - val_loss: 0.4389 - learning_rate: 3.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8505 - loss: 0.3500\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.82247\n",
            "\n",
            "Epoch 12: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 497ms/step - accuracy: 0.8505 - loss: 0.3500 - val_accuracy: 0.7985 - val_loss: 0.4618 - learning_rate: 3.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8575 - loss: 0.3421\n",
            "Epoch 13: val_accuracy did not improve from 0.82247\n",
            "\n",
            "Epoch 13: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 499ms/step - accuracy: 0.8575 - loss: 0.3421 - val_accuracy: 0.8091 - val_loss: 0.4497 - learning_rate: 9.0000e-06\n",
            "Epoch 14/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8674 - loss: 0.3264\n",
            "Epoch 14: val_accuracy improved from 0.82247 to 0.82930, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_best.keras\n",
            "\n",
            "Epoch 14: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 499ms/step - accuracy: 0.8674 - loss: 0.3264 - val_accuracy: 0.8293 - val_loss: 0.3999 - learning_rate: 9.0000e-06\n",
            "Epoch 15/15\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.8648 - loss: 0.3264\n",
            "Epoch 15: val_accuracy did not improve from 0.82930\n",
            "\n",
            "Epoch 15: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 500ms/step - accuracy: 0.8648 - loss: 0.3264 - val_accuracy: 0.8145 - val_loss: 0.4366 - learning_rate: 9.0000e-06\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8273 - loss: 0.4012\n",
            "\n",
            "‚úÖ Test Accuracy: 0.8306\n",
            "‚òÅÔ∏è Final model saved to Drive at: /content/drive/MyDrive/custom_cnn_real_vs_fake/custom_cnn_final.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# =========================\n",
        "# üìÅ Paths\n",
        "# =========================\n",
        "train_dir = \"/content/data/train\"\n",
        "val_dir = \"/content/data/val\"\n",
        "test_dir = \"/content/data/test\"\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# ‚öôÔ∏è Parameters\n",
        "# =========================\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20  # increase epochs for better fine-tuning\n",
        "\n",
        "# =========================\n",
        "# üîÑ Data Augmentation & Normalization\n",
        "# =========================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=[0.85,1.2],\n",
        "    brightness_range=[0.8,1.2],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,  # if valid for your dataset\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# =========================\n",
        "# üì¶ Load Datasets\n",
        "# =========================\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# üß© Upgraded CNN Model\n",
        "# =========================\n",
        "def build_custom_cnn(input_shape=(256, 256, 3)):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # Block 1\n",
        "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # Block 2\n",
        "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # Block 3\n",
        "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # Block 4\n",
        "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # Global Average Pooling instead of Flatten\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.6),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_custom_cnn()\n",
        "\n",
        "# =========================\n",
        "# üß† Compile Model\n",
        "# =========================\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),  # smaller base LR\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# üî• Callbacks\n",
        "# =========================\n",
        "checkpoint_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(save_dir, \"custom_cnn_best.keras\"),\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint_last = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(save_dir, \"custom_cnn_last.keras\"),\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.3, patience=3, verbose=1, min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=6, restore_best_weights=True\n",
        ")\n",
        "\n",
        "callbacks = [checkpoint_best, checkpoint_last, reduce_lr, early_stop]\n",
        "\n",
        "# =========================\n",
        "# üöÄ Train\n",
        "# =========================\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Training interrupted ‚Äî saving model progress...\")\n",
        "    model.save(os.path.join(save_dir, \"custom_cnn_interrupted.keras\"))\n",
        "\n",
        "# =========================\n",
        "# ‚úÖ Evaluate on Test Set\n",
        "# =========================\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# =========================\n",
        "# üíæ Save Final Model\n",
        "# =========================\n",
        "final_path = os.path.join(save_dir, \"custom_cnn_final.keras\")\n",
        "model.save(final_path)\n",
        "print(f\"‚òÅÔ∏è Final model saved to Drive at: {final_path}\")\n"
      ],
      "metadata": {
        "id": "oQUNj_hvFogH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352a1d6a-e3f0-41d0-ed1e-8441c5cf6d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 27913 images belonging to 2 classes.\n",
            "Found 5999 images belonging to 2 classes.\n",
            "Found 5998 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.6554 - loss: 0.6632\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75729, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 1: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 620ms/step - accuracy: 0.6554 - loss: 0.6632 - val_accuracy: 0.7573 - val_loss: 0.5384 - learning_rate: 5.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.7318 - loss: 0.5609\n",
            "Epoch 2: val_accuracy improved from 0.75729 to 0.78130, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 2: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 603ms/step - accuracy: 0.7318 - loss: 0.5609 - val_accuracy: 0.7813 - val_loss: 0.5005 - learning_rate: 5.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.7658 - loss: 0.5198\n",
            "Epoch 3: val_accuracy did not improve from 0.78130\n",
            "\n",
            "Epoch 3: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 604ms/step - accuracy: 0.7658 - loss: 0.5198 - val_accuracy: 0.7370 - val_loss: 0.6099 - learning_rate: 5.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.7849 - loss: 0.4932\n",
            "Epoch 4: val_accuracy did not improve from 0.78130\n",
            "\n",
            "Epoch 4: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 606ms/step - accuracy: 0.7849 - loss: 0.4932 - val_accuracy: 0.7775 - val_loss: 0.5030 - learning_rate: 5.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.7945 - loss: 0.4795\n",
            "Epoch 5: val_accuracy improved from 0.78130 to 0.81897, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 5: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 601ms/step - accuracy: 0.7945 - loss: 0.4795 - val_accuracy: 0.8190 - val_loss: 0.4527 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.8101 - loss: 0.4676\n",
            "Epoch 6: val_accuracy improved from 0.81897 to 0.82764, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 6: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 604ms/step - accuracy: 0.8101 - loss: 0.4676 - val_accuracy: 0.8276 - val_loss: 0.4460 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.8103 - loss: 0.4578\n",
            "Epoch 7: val_accuracy did not improve from 0.82764\n",
            "\n",
            "Epoch 7: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 605ms/step - accuracy: 0.8103 - loss: 0.4578 - val_accuracy: 0.7770 - val_loss: 0.5101 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.8196 - loss: 0.4430\n",
            "Epoch 8: val_accuracy did not improve from 0.82764\n",
            "\n",
            "Epoch 8: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 604ms/step - accuracy: 0.8196 - loss: 0.4430 - val_accuracy: 0.8231 - val_loss: 0.4422 - learning_rate: 5.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.8192 - loss: 0.4454\n",
            "Epoch 9: val_accuracy did not improve from 0.82764\n",
            "\n",
            "Epoch 9: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 600ms/step - accuracy: 0.8192 - loss: 0.4454 - val_accuracy: 0.8180 - val_loss: 0.4499 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.8303 - loss: 0.4327\n",
            "Epoch 10: val_accuracy improved from 0.82764 to 0.84197, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 10: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 604ms/step - accuracy: 0.8303 - loss: 0.4327 - val_accuracy: 0.8420 - val_loss: 0.4125 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.8295 - loss: 0.4267\n",
            "Epoch 11: val_accuracy did not improve from 0.84197\n",
            "\n",
            "Epoch 11: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 606ms/step - accuracy: 0.8295 - loss: 0.4267 - val_accuracy: 0.8323 - val_loss: 0.4360 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.8351 - loss: 0.4201\n",
            "Epoch 12: val_accuracy did not improve from 0.84197\n",
            "\n",
            "Epoch 12: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 605ms/step - accuracy: 0.8351 - loss: 0.4201 - val_accuracy: 0.8145 - val_loss: 0.4566 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.8375 - loss: 0.4148\n",
            "Epoch 13: val_accuracy did not improve from 0.84197\n",
            "\n",
            "Epoch 13: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 601ms/step - accuracy: 0.8375 - loss: 0.4148 - val_accuracy: 0.8381 - val_loss: 0.4173 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.8484 - loss: 0.4002\n",
            "Epoch 14: val_accuracy improved from 0.84197 to 0.85514, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 14: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 605ms/step - accuracy: 0.8484 - loss: 0.4002 - val_accuracy: 0.8551 - val_loss: 0.3926 - learning_rate: 1.5000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.8530 - loss: 0.3903\n",
            "Epoch 15: val_accuracy improved from 0.85514 to 0.85748, saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\n",
            "\n",
            "Epoch 15: saving model to /content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_last.keras\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 604ms/step - accuracy: 0.8530 - loss: 0.3903 - val_accuracy: 0.8575 - val_loss: 0.3871 - learning_rate: 1.5000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m 26/873\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m8:27\u001b[0m 599ms/step - accuracy: 0.8370 - loss: 0.4163"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sVdTULIGym7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Mount Drive (if not already)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"/content/drive/MyDrive/custom_cnn_real_vs_fake_upgrade/custom_cnn_best.keras\"\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "aI-GCw37g_ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329a5d4a-9146-4af5-ae21-c89a3e548c7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Path to your image\n",
        "img_path = \"/content/real.avif\"\n",
        "\n",
        "# Load image and resize to model input size\n",
        "img = image.load_img(img_path, target_size=(256, 256))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array / 255.0  # Normalize\n"
      ],
      "metadata": {
        "id": "Ekaki81LOjG4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(img_array)\n",
        "print(\"Raw prediction:\", pred)\n",
        "label = \"REAL\" if pred[0][0] > 0.5 else \"FAKE\"\n",
        "print(f\"üß† Prediction: {label} (Confidence: {pred[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f64w_ar9PWoL",
        "outputId": "f1107883-3b38-409d-e733-3858e6165c52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Raw prediction: [[0.46327543]]\n",
            "üß† Prediction: FAKE (Confidence: 0.4633)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label = \"REAL\" if pred[0][0] > 0.5 else \"FAKE\"\n",
        "print(f\"üß† Prediction: {label} (Confidence: {pred[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMu7dlPBPY2P",
        "outputId": "46dfd03e-566e-4f0b-e941-2e6101fca819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Prediction: FAKE (Confidence: 0.0373)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred_value = pred[0][0]\n",
        "plt.bar([\"FAKE\", \"REAL\"], [1 - pred_value, pred_value])\n",
        "plt.title(f\"Prediction Confidence: {pred_value:.3f}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "PnwKCTvFP6gJ",
        "outputId": "1e40b21f-96bf-4d12-c6fa-3cd671cc0b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6aj7IHwP64Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}